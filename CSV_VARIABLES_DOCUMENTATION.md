# CSV Variables Documentation

This document describes all variables saved in the CSV files generated by the Social Recognition Memory Task.

## File Structure

The experiment generates three CSV files:
1. **recognition_study_[participant_id]_[timestamp].csv** - Study phase data
2. **recognition_trials_[participant_id]_[timestamp].csv** - Recognition phase data
3. **recognition_summary_[participant_id]_[timestamp].csv** - Experiment summary (total time)

The localizer task generates one CSV file:
4. **localizer_[participant_id]_[timestamp].csv** - Localizer task data

---

## Study Phase CSV Variables

### `block`
- **Type**: Integer
- **Description**: Block number (0 = practice block, 1-5 = experimental blocks)
- **Example**: `0`, `1`, `2`

### `phase`
- **Type**: String
- **Description**: Phase identifier, always "study" for study phase data
- **Example**: `"study"`

### `trial`
- **Type**: Integer
- **Description**: Trial number within the study phase (1-indexed)
- **Example**: `1`, `2`, `3`

### `image_path`
- **Type**: String
- **Description**: Full path to the studied image file (always IMAGE_X.png, never lures)
- **Example**: `"PLACEHOLDERS/IMAGE_5.png"`

### `image_onset`
- **Type**: Float (Unix timestamp)
- **Description**: Time when the image was displayed (in seconds since epoch)
- **Example**: `1764818171.2572181`

### `image_offset`
- **Type**: Float (Unix timestamp)
- **Description**: Time when the image was removed from display (in seconds since epoch)
- **Example**: `1764818172.2572181`

### `image_duration`
- **Type**: Float (seconds)
- **Description**: Duration the image was displayed (always 1.0 second, fixed - no jitter)
- **Example**: `1.0`

### `fixation_onset`
- **Type**: Float (Unix timestamp)
- **Description**: Time when the fixation cross appeared before this image
- **Note**: Fixation appears before EVERY image, including the first image
- **Example**: `1764818170.5`

### `fixation_offset`
- **Type**: Float (Unix timestamp)
- **Description**: Time when the fixation cross was removed
- **Example**: `1764818171.0`

### `fixation_duration`
- **Type**: Float (seconds)
- **Description**: Duration of the fixation cross before this image
- **Distribution**: Uniform random between 0.25-0.75 seconds (`random.uniform(0.25, 0.75)`)
- **Jitter**: Each fixation duration is independently drawn from uniform distribution
- **Note**: Fixation appears before EVERY image, including the first image
- **Example**: `0.523456789`, `0.312345`, `0.678901`

---

## Recognition Phase CSV Variables

### `block`
- **Type**: Integer
- **Description**: Block number (0 = practice block, 1-5 = experimental blocks)
- **Example**: `0`, `1`, `2`

### `trial`
- **Type**: Integer
- **Description**: Trial number within the recognition phase (1-indexed)
- **Example**: `1`, `2`, `3`

### `phase`
- **Type**: String
- **Description**: Phase identifier, always "recognition" for recognition phase data
- **Example**: `"recognition"`

### `trial_type`
- **Type**: String
- **Description**: Type of trial - either "studied" (original Image version) or "lure" (Lure version of the same object)
- **Example**: `"studied"`, `"lure"`

### `is_studied`
- **Type**: Boolean
- **Description**: True if this is a studied image (original), False if it's a lure
- **Example**: `True`, `False`

### `image_path`
- **Type**: String
- **Description**: Full path to the image shown (Image_XXX.jpg for studied, Lure_XXX.jpg for lures)
  - **Important**: For lures, this is the lure version of the **same object** that was studied (e.g., if `Image_041.jpg` was studied, the lure would be `Lure_041.jpg`, not a random lure from a different object)
- **Example**: `"STIMULI/FRUIT/Apple/Image_041.jpg"`, `"STIMULI/FRUIT/Apple/Lure_041.jpg"`

### `image_onset`
- **Type**: Float (Unix timestamp)
- **Description**: Time when the recognition image was displayed (in seconds since epoch)
- **Example**: `1764818192.494316`

### `participant_first`
- **Type**: Boolean
- **Description**: Always True - participant always responds first in all blocks
- **Example**: `True`

---

## Participant Response Variables

### `participant_slider_value`
- **Type**: Float (0.0 to 1.0)
- **Description**: Participant's confidence rating on the slider
  - Values closer to 0.0 = OLD (studied)
  - Values closer to 1.0 = NEW (lure)
  - 0.5 = center/uncertain
- **Example**: `0.3142361111111111`, `0.7890563378785669`

### `participant_rt`
- **Type**: Float (seconds)
- **Description**: Participant's reaction time from image onset to when they clicked SUBMIT
- **Timeout**: If participant doesn't respond within 7.0 seconds, random answer selected and RT = 7.0
- **Example**: `4.68976616859436`, `2.981760025024414`, `7.0` (timeout)

### `participant_commit_time`
- **Type**: Float (Unix timestamp)
- **Description**: Time when participant clicked the SUBMIT button
- **Example**: `1764818198.3314402`

### `participant_slider_timeout`
- **Type**: Boolean
- **Description**: True if participant timed out (didn't respond within 7.0 seconds)
- **Timeout duration**: 7.0 seconds (fixed, no jitter)
- **Example**: `True`, `False`

### `participant_slider_stop_time`
- **Type**: Float (Unix timestamp) or None
- **Description**: Time when participant clicked on the slider to set their rating. None if they never clicked on the slider.
- **Example**: `1764818195.5`, `None`

---

## AI/Partner Response Variables

### `ai_slider_value`
- **Type**: Float (0.0 to 1.0) or None
- **Description**: AI/partner's confidence rating on the slider
  - Values closer to 0.0 = OLD (studied)
  - Values closer to 1.0 = NEW (lure)
  - `None` for practice trial 1 (no AI response)
- **Example**: `0.6569413750565093`, `0.3563797294608513`, `None`

### `ai_rt`
- **Type**: Float (seconds)
- **Description**: AI's reaction time (drawn from log-normal distribution, capped at 5 seconds)
- **Distribution**: Log-normal with underlying normal parameters: mu = 0.5, sigma = 0.3
- **Mean RT**: Approximately 1.5-2.5 seconds
- **Maximum RT**: 5.0 seconds (capped)
- **Jitter**: Each trial draws independently from the distribution
- **Formula**: `min(np.random.lognormal(0.5, 0.3), 5.0)`
- **Example**: `2.2821904016769365`, `1.2902461381415058`, `4.5`

### `ai_decision_time`
- **Type**: Float (Unix timestamp) or None
- **Description**: Time when AI internally made its decision (right after make_decision() call)
- **Note**: `None` for practice trial 1 (no AI response)
- **Example**: `1764818198.338135`, `None`

### `ai_slider_display_time`
- **Type**: Float (Unix timestamp) or None
- **Description**: Time when AI's slider handle appears at the final position (when the slider value is visually set)
- **Note**: `None` for practice trial 1 (no AI response)
- **Example**: `1764818200.155891`, `None`

### `ai_final_slider_display_time`
- **Type**: Float (Unix timestamp) or None
- **Description**: Time when AI's submit button was clicked in the animation (visual commit time)
- **Note**: `None` for practice trial 1 (no AI response)
- **Example**: `1764818201.255891`, `None`

### `ai_correct`
- **Type**: Boolean or None
- **Description**: True if AI's decision was correct (matches ground truth), False otherwise
- **Note**: `None` for practice trial 1 (no AI response)
- **Example**: `True`, `False`, `None`

### `ai_reliability`
- **Type**: Float (0.0 to 1.0)
- **Description**: AI's accuracy rate/reliability for this trial
  - `0.75` = Reliable partner (Amy in blocks 1 and 4) - exactly 75% accurate using deterministic threshold
  - `0.25` = Unreliable partner (Ben in blocks 2, 3, and 5) - exactly 25% accurate using deterministic threshold
  - `0.5` = Practice block (50% reliability)
- **Note**: Accuracy rates are deterministic, not probabilistic. Reliable blocks use a hard threshold ensuring exactly 3 out of every 4 trials are correct. Unreliable blocks ensure exactly 1 out of every 4 trials is correct.
- **Example**: `0.75`, `0.25`, `0.5`

---

## Switch/Stay Decision Variables

### `switch_stay_decision`
- **Type**: String
- **Description**: Participant's decision - "stay" (keep own answer) or "switch" (use partner's answer)
- **Example**: `"stay"`, `"switch"`

### `switch_rt`
- **Type**: Float (seconds) or None
- **Description**: Reaction time from when decision screen appeared to when participant clicked STAY or SWITCH
- **Note**: `None` for practice trials 1 and 2 (no switch/stay decision screen shown)
- **Example**: `2.829475164413452`, `1.4260890483856201`, `None`

### `switch_commit_time`
- **Type**: Float (Unix timestamp)
- **Description**: Time when participant clicked STAY or SWITCH button
- **Example**: `1764818206.231731`

### `switch_timeout`
- **Type**: Boolean or None
- **Description**: True if participant timed out on switch/stay decision (didn't respond within 7.0 seconds)
- **Timeout duration**: 7.0 seconds (fixed, no jitter)
- **Note**: `None` for practice trials 1 and 2 (no switch/stay decision screen shown)
- **Example**: `True`, `False`, `None`

### `decision_onset_time`
- **Type**: Float (Unix timestamp)
- **Description**: Time when the switch/stay decision screen appeared with all information
- **Example**: `1764818203.4`

---

## Final Answer and Accuracy Variables

### `final_answer`
- **Type**: Float (0.0 to 1.0)
- **Description**: Final answer used for scoring (participant's value if stayed, AI's value if switched)
- **Example**: `0.0`, `0.3563797294608513`

### `used_ai_answer`
- **Type**: Boolean
- **Description**: True if final answer came from AI (participant switched), False if from participant (stayed)
- **Example**: `True`, `False`

### `ground_truth`
- **Type**: Float
- **Description**: Correct answer (0.0 for studied/OLD, 1.0 for lure/NEW)
- **Example**: `0.0`, `1.0`

### `participant_accuracy`
- **Type**: Boolean
- **Description**: True if final answer was correct (within 0.5 of ground truth), False otherwise
- **Example**: `True`, `False`

---

## Distance Metrics

### `euclidean_participant_to_truth`
- **Type**: Float
- **Description**: Euclidean distance between participant's slider value and ground truth
  - Lower values = closer to correct answer
- **Example**: `0.3142361111111111`, `0.0`

### `euclidean_ai_to_truth`
- **Type**: Float or None
- **Description**: Euclidean distance between AI's slider value and ground truth
  - Lower values = closer to correct answer
- **Note**: `None` for practice trial 1 (no AI response)
- **Example**: `0.6569413750565093`, `0.0`, `None`

### `euclidean_participant_to_ai`
- **Type**: Float
- **Description**: Euclidean distance between participant's and AI's slider values
  - Lower values = more similar ratings
- **Example**: `0.6569413750565093`, `0.042143618349740175`

---

## Outcome Variables

### `outcome_time`
- **Type**: Float (Unix timestamp) or None
- **Description**: Time when the outcome screen (Correct/Incorrect) was displayed
- **Note**: `None` for practice trials 1 and 2 (outcome not tracked separately)
- **Example**: `1764818206.237804`, `None`

### `block_start_time`
- **Type**: Float (Unix timestamp)
- **Description**: Time when the block started (when study phase began)
- **Example**: `1764818000.0`

### `block_end_time`
- **Type**: Float (Unix timestamp) or None
- **Description**: Time when the block ended (after block summary screen)
- **Note**: `None` for practice block (block 0) - practice block timing not tracked
- **Example**: `1764818300.0`, `None`

### `block_duration_seconds`
- **Type**: Float (seconds)
- **Description**: Total duration of the block in seconds (from start of study phase to end of block summary)
- **Example**: `300.5`

### `block_duration_minutes`
- **Type**: Float (minutes) or None
- **Description**: Total duration of the block in minutes
- **Note**: `None` for practice block (block 0) - practice block timing not tracked
- **Example**: `5.008`, `None`

### `points_earned`
- **Type**: Float
- **Description**: Points earned this trial (based on Euclidean distance from correct answer)
  - Formula: `1.0 - euclidean_distance(final_answer, ground_truth)`
  - Range: 0.0 to 1.0
  - Based on correctness only (Euclidean distance from correct answer)
- **Example**: `0.6857638888888889`, `0.0`, `1.0`

---

## Summary CSV Variables

The **recognition_summary_[participant_id]_[timestamp].csv** file contains overall experiment summary data.

### `participant_id`
- **Type**: String
- **Description**: Participant identifier
- **Example**: `"kini"`, `"P001"`

### `experiment_start_time`
- **Type**: Float (Unix timestamp)
- **Description**: Time when experiment started (after initial instructions)
- **Example**: `1764818000.0`

### `experiment_end_time`
- **Type**: Float (Unix timestamp)
- **Description**: Time when experiment ended (after final instructions)
- **Example**: `1764820800.0`

### `total_task_time_seconds`
- **Type**: Float (seconds)
- **Description**: Total duration of the experiment in seconds
- **Example**: `2800.5`

### `total_task_time_minutes`
- **Type**: Float (minutes)
- **Description**: Total duration of the experiment in minutes
- **Example**: `46.675`

---

## Notes

- All timestamps are in Unix time (seconds since January 1, 1970)
- All slider values range from 0.0 (OLD/studied) to 1.0 (NEW/lure)
- Timeout variables are True if the participant didn't respond within the time limit:
  - Slider and switch/stay decisions: 7 seconds
- The experiment saves data incrementally after each trial, not just at the end
- Block 0 is the practice block (3 trials), blocks 1-5 are experimental blocks (20 trials each)
- **Narrative context**: The experiment is framed as a photography studio collaboration where participants work with Amy (reliable partner) or Ben (unreliable partner) to help sort images for an exhibition. Scoring is framed as "in-house curator" evaluations.
- **Scoring display**: Trial outcomes show "The in-house curator scored this image: X points" instead of "Points earned this trial". Block summaries show "The in-house curator scored this collection X points out of a total of 20 points!" (actual points, not scaled).
- Points are calculated based on Euclidean distance: `points = 1.0 - distance(final_answer, ground_truth)`
- **Practice Block (Block 0)**:
  - Contains 3 practice trials with simplified stimuli (colored shapes)
  - All practice trials include the same fields as regular trials
  - Fields that don't apply to specific practice trials are set to `None` or `False`:
    - Trial 1: No AI response (`ai_slider_value`, `ai_rt`, `ai_decision_time`, `ai_slider_display_time`, `ai_final_slider_display_time`, `ai_correct` all `None`), no switch/stay decision (all switch fields `None`), `euclidean_ai_to_truth` and `euclidean_participant_to_ai` are `None`. `ai_reliability` is `0.5` (50% for practice block)
    - Trial 2: Has AI response, but no switch/stay decision (switch fields `None`). `ai_reliability` is `0.5` (50% for practice block)
    - Trial 3: Full trial with participant, AI, and switch/stay decision. `ai_reliability` is `0.5` (50% for practice block)
  - All practice trials have `block_start_time`, `block_end_time`, `block_duration_seconds`, and `block_duration_minutes` set to `None` (practice block timing not tracked)
- **Block structure**:
  - Block 1: Reliable (exactly 0.75 accuracy, deterministic), Participant first
  - Block 2: Unreliable (exactly 0.25 accuracy, deterministic), Participant first
  - Block 3: Unreliable (exactly 0.25 accuracy, deterministic), Participant first
  - Block 4: Reliable (exactly 0.75 accuracy, deterministic), Participant first
  - Block 5: Unreliable (exactly 0.25 accuracy, deterministic), Participant first
  
  **AI Accuracy Implementation**: The AI collaborator uses deterministic thresholds to ensure exact accuracy rates:
  - **75% accuracy (Reliable blocks)**: Exactly 3 out of every 4 trials are correct (positions 1, 2, 3 in each group of 4)
  - **25% accuracy (Unreliable blocks)**: Exactly 1 out of every 4 trials is correct (position 1 in each group of 4)
  - In a 20-trial block, reliable blocks will have exactly 15 correct trials, unreliable blocks will have exactly 5 correct trials
- **Turn-taking**: Participant always goes first in all blocks
- **Study phase timing**:
  - Images are shown for **1.0 second each** (fixed duration, no jitter)
  - **Jittered fixations** appear before EVERY image: **0.25-0.75 seconds** (uniform random distribution)
  - Fixation jitter: `random.uniform(0.25, 0.75)` - each fixation independently drawn
  - Fixation appears before the first image and between all subsequent images
  - 20 fixations per block (before each of the 20 images)
  - Total study phase duration: ~30-35 seconds (varies due to fixation jitter)
- **Recognition phase timing**:
  - **Pre-trial fixation**: 0.5 seconds (fixed duration, shown before each image)
  - Images are shown for **1.0 second each** (fixed duration, no jitter)
    - Image remains visible until participant responds or timeout (7 seconds)
  - **Jittered fixations** appear between trials: **0.25-0.75 seconds** (uniform random distribution)
  - Inter-trial jitter: `random.uniform(0.25, 0.75)` - each jitter independently drawn
  - Jitter shown as fixation cross during the inter-trial interval
  - **No jitter after the last trial** in each block
  - **19 jittered fixations per block** (between 20 trials)
  - Participant slider timeout: **7.0 seconds** (fixed)
  - AI RT: Log-normal distribution (mu=0.5, sigma=0.3), capped at 5.0 seconds
- **Switch/stay decision timing**:
  - Decision timeout: **7.0 seconds** (fixed)
- **Block timing**: `block_start_time`, `block_end_time`, and `block_duration_seconds`/`block_duration_minutes` are added to all trials within a block. These values are updated at the end of each block, so they represent the complete block duration from study phase start to block summary completion.

---

## Localizer Task CSV Variables

The **localizer_[participant_id]_[timestamp].csv** file contains data from the localizer task, where participants view 100 images in random order and answer category questions at every 10th image.

### `participant_id`
- **Type**: String
- **Description**: Participant identifier
- **Example**: `"P001"`, `"test_user"`

### `trial`
- **Type**: Integer
- **Description**: Trial number when the question was asked (always a multiple of 10: 10, 20, 30, ..., 100)
- **Example**: `10`, `20`, `30`, `100`

### `stimulus_number`
- **Type**: Integer (1-100)
- **Description**: The stimulus number of the image that was shown (from Image_001.jpg to Image_100.jpg)
- **Example**: `1`, `42`, `100`

### `object_name`
- **Type**: String
- **Description**: Name of the object folder containing the image (e.g., "Apple", "Car", "Elephant")
- **Example**: `"Apple"`, `"Car"`, `"Elephant"`

### `category`
- **Type**: String
- **Description**: Category folder name that the image belongs to
- **Possible values**: `"BIG_ANIMAL"`, `"BIG_OBJECT"`, `"BIRD"`, `"FOOD"`, `"FRUIT"`, `"INSECT"`, `"SMALL_ANIMAL"`, `"SMALL_OBJECT"`, `"VEGETABLE"`, `"VEHICLE"`
- **Example**: `"FRUIT"`, `"BIG_ANIMAL"`

### `question_category`
- **Type**: String
- **Description**: The category that was asked about in the question (same as `category` since we ask about the image's actual category)
- **Possible values**: Same as `category`
- **Example**: `"FRUIT"`, `"BIG_ANIMAL"`

### `question_text`
- **Type**: String
- **Description**: Full text of the question asked to the participant
- **Format**: "Was the last object a [category]?" where category is converted from folder name (e.g., "BIG_ANIMAL" → "big animal")
- **Example**: `"Was the last object a big animal?"`, `"Was the last object a fruit?"`

### `answer`
- **Type**: Boolean
- **Description**: Participant's response to the question (True = YES, False = NO)
- **Example**: `True`, `False`

### `correct_answer`
- **Type**: Boolean
- **Description**: The correct answer to the question (always True, since we ask about the category the image actually belongs to)
- **Example**: `True`

### `correct`
- **Type**: Boolean
- **Description**: Whether the participant's answer matches the correct answer (True if correct, False if incorrect)
- **Example**: `True`, `False`

---

## Localizer Task CSV Variables

The localizer task generates one CSV file:
- **localizer_[participant_id]_[timestamp].csv** - Localizer task data

**File Format**: Each row represents one image presentation. Question trials (every 10th image) include question response data.

### `participant_id`
- **Type**: String
- **Description**: Participant identifier
- **Example**: `"kini"`, `"P001"`

### `trial`
- **Type**: Integer
- **Description**: Trial number (1-indexed, 1-200)
- **Note**: Questions are asked at trials 10, 20, 30, ..., 200 (every 10th trial)
- **Example**: `1`, `10`, `50`, `200`

### `stimulus_number`
- **Type**: Integer (1-100)
- **Description**: The stimulus number of the image (from Image_001.jpg to Image_100.jpg, or corresponding Lure)
- **Example**: `1`, `42`, `100`

### `object_name`
- **Type**: String
- **Description**: Name of the object folder containing the image (e.g., "Apple", "Car", "Elephant")
- **Example**: `"Apple"`, `"Car"`, `"Elephant"`

### `category`
- **Type**: String
- **Description**: Category folder name that the image belongs to
- **Possible values**: `"BIG_ANIMAL"`, `"BIG_OBJECT"`, `"BIRD"`, `"FOOD"`, `"FRUIT"`, `"INSECT"`, `"SMALL_ANIMAL"`, `"SMALL_OBJECT"`, `"VEGETABLE"`, `"VEHICLE"`
- **Example**: `"FRUIT"`, `"BIG_ANIMAL"`

### `stimulus_type`
- **Type**: String
- **Description**: Type of stimulus shown
- **Possible values**: `"Image"` (original image), `"Lure"` (lure version)
- **Example**: `"Image"`, `"Lure"`

### `is_lure`
- **Type**: Boolean
- **Description**: True if this is a lure stimulus, False if it's an original Image
- **Example**: `True`, `False`

### `presentation_time`
- **Type**: String (datetime format)
- **Description**: Timestamp when the image was displayed
- **Format**: `"YYYY-MM-DD HH:MM:SS.ffffff"`
- **Example**: `"2026-01-30 23:21:31.123456"`

### `is_question_trial`
- **Type**: Boolean
- **Description**: True if this trial included a category question (trials 10, 20, 30, ..., 200), False otherwise
- **Example**: `True`, `False`

### `question_category`
- **Type**: String or None
- **Description**: The category that was asked about in the question (only populated for question trials)
- **Possible values**: Same as `category`, or `None` for non-question trials
- **Example**: `"FRUIT"`, `"BIG_ANIMAL"`, `None`

### `question_text`
- **Type**: String or None
- **Description**: Full text of the question asked to the participant (only populated for question trials)
- **Format**: "Was the last object a [category]?" where category is converted from folder name (e.g., "BIG_ANIMAL" → "big animal")
- **Example**: `"Was the last object a big animal?"`, `"Was the last object a fruit?"`, `None`

### `answer`
- **Type**: Boolean, String, or None
- **Description**: Participant's response to the question
- **Possible values**: 
  - `True` (YES) for question trials where participant answered YES
  - `False` (NO) for question trials where participant answered NO
  - `"TIMEOUT"` if participant timed out (though localizer has no timeout)
  - `None` for non-question trials
- **Example**: `True`, `False`, `None`

### `correct_answer`
- **Type**: Boolean or None
- **Description**: The correct answer to the question (always True for question trials, since we ask about the category the image actually belongs to)
- **Example**: `True`, `None`

### `correct`
- **Type**: Boolean or None
- **Description**: Whether the participant's answer matches the correct answer
- **Possible values**: `True` (correct), `False` (incorrect), `None` (non-question trial or timeout)
- **Example**: `True`, `False`, `None`

### `timed_out`
- **Type**: Boolean or None
- **Description**: Whether the participant timed out on the question (always False for localizer, as there is no timeout)
- **Example**: `False`, `None`

### `response_time`
- **Type**: Float (seconds) or None
- **Description**: Time taken to respond to the question, measured from question onset to button press
- **Example**: `1.234`, `2.567`, `None`

---

## Notes on Localizer Task

- **Image presentation timing**:
  - Each image is displayed for **1.0 second** (fixed duration, no jitter)
  - **0.5 second pause** between images (fixed, no jitter)
  - Total images: 200 (100 Image + 100 Lure versions)
  - Total image presentation time: 200 images × 1.0 second = 200 seconds (~3.3 minutes)
  - Total inter-image pause time: 199 pauses × 0.5 seconds = 99.5 seconds
  - Total task duration: ~300 seconds (~5 minutes) plus question response times
- **Question timing**:
  - Questions are asked at trials 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200 (20 questions total)
  - **No timeout** for questions - participant must respond (YES/NO buttons)
  - Question appears immediately after the image is shown
- **Category conversion**: Category names are converted from folder format (e.g., "BIG_ANIMAL") to natural language (e.g., "big animal") for the question
- **Correct answer**: The correct answer is always True since we ask about the category the image actually belongs to
- **File saving**: 
  - Skipped if "test" (case-insensitive) is in the participant name
  - For touch screen mode: files saved to `../LOG_FILES/` directory
  - For click/mouse mode: files saved to the current directory
  - File naming format: `localizer_[participant_id]_[timestamp].csv`
  - Example: `localizer_kini_20260130_232131.csv`

